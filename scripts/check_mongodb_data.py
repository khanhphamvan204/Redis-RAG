"""
Quick script to check MongoDB collections for Spark analytics data
"""
from pymongo import MongoClient
import json
from datetime import datetime

# Connect to MongoDB
client = MongoClient("mongodb://127.0.0.1:27017/faiss_db")
db = client["faiss_db"]

print("=" * 60)
print("CHECKING MONGODB COLLECTIONS FOR ANALYTICS DATA")
print("=" * 60)

# Expected collections from Spark
spark_collections = [
    "query_analytics_by_faculty",
    "query_analytics_by_year", 
    "query_analytics_heatmap"
]

# Also check raw query logs
all_collections = ["query_logs"] + spark_collections

for coll_name in all_collections:
    print(f"\nğŸ“Š Collection: {coll_name}")
    print("-" * 60)
    
    try:
        collection = db[coll_name]
        count = collection.count_documents({})
        
        if count == 0:
            print(f"   âŒ Empty (0 documents)")
        else:
            print(f"   âœ… Found {count} documents")
            
            # Show sample document
            sample = collection.find_one()
            if sample:
                # Remove _id for cleaner display
                if '_id' in sample:
                    del sample['_id']
                print(f"\n   Sample document:")
                print(f"   {json.dumps(sample, indent=2, default=str)}")
                
    except Exception as e:
        print(f"   âš ï¸  Error: {e}")

print("\n" + "=" * 60)
print("SUMMARY")
print("=" * 60)

# Check if pipeline is working
query_logs_count = db["query_logs"].count_documents({})
faculty_count = db["query_analytics_by_faculty"].count_documents({})
year_count = db["query_analytics_by_year"].count_documents({})
heatmap_count = db["query_analytics_heatmap"].count_documents({})

print(f"\nğŸ“ˆ Data Pipeline Status:")
print(f"   Raw Queries (MongoDB): {query_logs_count}")
print(f"   Faculty Analytics (Spark): {faculty_count}")
print(f"   Year Analytics (Spark): {year_count}")
print(f"   Heatmap Data (Spark): {heatmap_count}")

if query_logs_count > 0:
    print(f"\nâœ… Query tracking is working!")
    if faculty_count == 0 and year_count == 0:
        print(f"âš ï¸  But Spark aggregations not found yet.")
        print(f"   â†’ Check if Spark Streaming container is running")
        print(f"   â†’ Check Spark logs: docker logs spark-streaming")
else:
    print(f"\nâŒ No query logs found!")
    print(f"   â†’ Make some queries in the chat UI to generate data")

client.close()
